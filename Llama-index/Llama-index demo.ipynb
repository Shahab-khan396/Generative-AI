{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a2oVcH9mvQF_"
      },
      "outputs": [],
      "source": [
        "!pip install llama-index-vector-stores-chroma chromadb"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T1I-Tca9vRSV"
      },
      "outputs": [],
      "source": [
        "!pip install llama-index-llms-openrouter"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "NFQYTQCsufYg"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "from llama_index.core import VectorStoreIndex, SimpleDirectoryReader, Settings\n",
        "from llama_index.embeddings.huggingface import HuggingFaceEmbedding\n",
        "from llama_index.llms.openrouter import OpenRouter\n",
        "from llama_index.core.node_parser import SentenceSplitter\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p_A7qtnJuhit",
        "outputId": "1f3815e9-51ba-4a99-a75b-95318039b29e"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# === 1. Set up free embedding model (Hugging Face) ===\n",
        "Settings.embed_model = HuggingFaceEmbedding(\n",
        "    model_name=\"BAAI/bge-small-en-v1.5\"\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qADyiFwgujgI"
      },
      "outputs": [],
      "source": [
        "# === 2. Set up free LLM via OpenRouter ===\n",
        "Settings.llm = OpenRouter(\n",
        "    model=\"deepseek/deepseek-r1-0528-qwen3-8b:free\",  # Free tier model\n",
        "    api_key=\"\",\n",
        "    max_tokens=512\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "eWsknbP_ul-5"
      },
      "outputs": [],
      "source": [
        "\n",
        "# === 3. Load documents ===\n",
        "documents = SimpleDirectoryReader(\"data\").load_data()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "SoHtZCIwuneA"
      },
      "outputs": [],
      "source": [
        "# Optional: Better chunking\n",
        "node_parser = SentenceSplitter(chunk_size=512, chunk_overlap=50)\n",
        "nodes = node_parser.get_nodes_from_documents(documents)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "Tabo0oBxurEB"
      },
      "outputs": [],
      "source": [
        "\n",
        "# === 4. Create index with Chroma (local vector DB) ===\n",
        "from llama_index.vector_stores.chroma import ChromaVectorStore\n",
        "import chromadb\n",
        "\n",
        "\n",
        "chroma_client = chromadb.PersistentClient(path=\"./chroma_db\")\n",
        "chroma_collection = chroma_client.create_collection(\"quickstart\")\n",
        "vector_store = ChromaVectorStore(chroma_collection=chroma_collection)\n",
        "index = VectorStoreIndex(nodes=nodes, vector_store=vector_store)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ikfw1OXJvtHi"
      },
      "outputs": [],
      "source": [
        "# === 5. Query Engine ===\n",
        "query_engine = index.as_query_engine(similarity_top_k=3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EmE986SZqlUz",
        "outputId": "f151c03d-eee9-432f-b438-0c35316d1f8a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Answer:\n",
            "Shahab Khan is a Full-Stack AI Engineer and Computer Science student with expertise in machine learning, deep learning, generative AI, and AI automation. He has experience developing end-to-end AI solutions using frameworks like TensorFlow, Hugging Face, LangChain, and n8n. His skills include parameter-efficient fine-tuning of models like LLaMA 3.2, building chatbot workflows, and integrating LLMs and APIs for automation. He is also pursuing a Bachelor's degree in Computer Science and has upcoming certifications in Azure AI Fundamentals, Deep Learning, and Machine Learning with Python.\n",
            "\n",
            "Answer:\n",
            "I can't answer that question.\n"
          ]
        }
      ],
      "source": [
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# === 6. Ask questions ===\n",
        "response = query_engine.query(\"who is shahab khan?\")\n",
        "print(\"\\nAnswer:\")\n",
        "print(response)\n",
        "\n",
        "response = query_engine.query(\"How does OpenRouter help?\")\n",
        "print(\"\\nAnswer:\")\n",
        "print(response)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RgTYunjhvlpp"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
